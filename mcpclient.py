import asyncio
from mcp import ClientSession,StdioServerParameters
from mcp.client.stdio import stdio_client
from openai import OpenAI
import json

with open("config.json","r") as f:
    config = json.load(f)
    
api_key = config['api_key']
base_url = config['base_url']


client = OpenAI(
    api_key=api_key,
    base_url=base_url
)


# é…ç½®ä½ çš„ MCP Server è·¯å¾„ 
server_params = StdioServerParameters(
    command="/Users/mac/anaconda3/envs/hugface/bin/python", # å½“å‰è™šæ‹Ÿç¯å¢ƒçš„ python ä½ç½®
    args=["/Users/mac/Documents/mcp/mcp/stock_mcp_server.py"], # mcp server ä½ç½®
)

async def main():
    # å¯åŠ¨å¹¶é“¾æ¥æœ¬åœ° MCP Server
    async with stdio_client(server_params) as (read,write):
        async with ClientSession(read,write) as session:
            # åˆå§‹åŒ–è¿æ¥
            await session.initialize()

            # è·å–server é‡Œå®šä¹‰çš„ tools
            mcp_tools = await session.list_tools()
            print("\n" + "="*30)
            print("ğŸ›¡ï¸  å½“å‰å·²åŠ è½½çš„ MCP å·¥å…·æ¸…å•:")
            print("="*30)

            for tool in mcp_tools.tools:
                print(f"ğŸ”§ å·¥å…·åç§°: {tool.name}")
                print(f"ğŸ“ åŠŸèƒ½æè¿°: {tool.description}")
                print(f"ğŸ“Š è¾“å…¥å‚æ•°: {tool.inputSchema.get('properties', {}).keys()}")
                print("-" * 30)

            # å°† MCPå·¥å…·è½¬åŒ–ä¸ºå¤§æ¨¡å‹ API èƒ½å¤Ÿè¯†åˆ«çš„æ ¼å¼
            # è¿™ä¸ªè¿‡ç¨‹å’Œå•ä¸€è®©API è°ƒç”¨å·¥å…·æ˜¯ä¸€è‡´çš„
            available_tools = [{
                "type":"function",
                "function":{
                    "name":tool.name,
                    "description":tool.description, # è¿™é‡Œè·å–çš„tool.descriptionå°±æ˜¯ tool çš„æ³¨é‡Š
                    "parameters" :tool.inputSchema
                } 
            } for tool in mcp_tools.tools
            ]
            messages = [{
                "role":"user",
                "content":"å¸®æˆ‘æŸ¥ä¸€ä¸‹æ¯”äºšè¿ªçš„è‚¡ç¥¨ä»·æ ¼ï¼Œå¹¶ç»™å‡ºä½ çš„çœ‹æ³•"
            }]

            response = client.chat.completions.create(
                model = "intern-s1",
                messages = messages,
                tools = available_tools
            )

            message = response.choices[0].message

            # å¦‚æœæ¨¡å‹å†³å®šè°ƒç”¨å·¥å…·
            if message.tool_calls:
                messages.append(message)
                for tool_call in message.tool_calls:
                    args = json.loads(tool_call.function.arguments)
                    tool_result = await session.call_tool(
                        tool_call.function.name,
                        args
                    )
                    tool_output = "".join([
                        content.text 
                        for content in tool_result.content 
                        if hasattr(content, 'text')
                    ])
                    print(f"DEBUG - å‘ç»™æ¨¡å‹çš„ç»“æœå†…å®¹: {tool_output}")
                    print(f"\nğŸ¤– æ¨¡å‹å†³ç­–ï¼šè°ƒç”¨å·¥å…· [{tool_call.function.name}]")
                    print(f"ğŸ“¥ æå–å‚æ•°ï¼š{tool_call.function.arguments}")
                    # å°†è¿è¡Œç»“æœå­˜å…¥å¯¹è¯å†å²
                    messages.append({
                        "role":"tool",
                        "tool_call_id":tool_call.id,
                        "content":tool_output
                    })

                # ç¬¬äºŒæ¬¡è¯·æ±‚ï¼Œè®©æ¨¡å‹æ ¹æ®å·¥å…·ç»“æœç»™å‡ºå›ç­”
                final_response = client.chat.completions.create(
                    model = "intern-s1",
                    messages = messages,
                    tools = available_tools, 
                    tool_choice = "auto"
                )
                print(f"\nAI çš„å›ç­”ï¼š\n{final_response.choices[0].message.content}")
            else:
                print(f"\nAI çš„ç›´æ¥å›ç­”ï¼š\n{message.content}")

if __name__ == "__main__":
    asyncio.run(main())



